diff --git a/dbms/src/Interpreters/Aggregator.cpp b/dbms/src/Interpreters/Aggregator.cpp
index 07a9d8efc50..45d5d71f92a 100644
--- a/dbms/src/Interpreters/Aggregator.cpp
+++ b/dbms/src/Interpreters/Aggregator.cpp
@@ -1109,9 +1111,8 @@ BlocksList Aggregator::prepareBlocksAndFillTwoLevelImpl(
     AggregatedDataVariants & data_variants,
     Method & method,
     bool final,
-    ThreadPool * thread_pool) const
+    size_t max_threads) const
 {
-    size_t max_threads = thread_pool ? thread_pool->size() : 1;
     if (max_threads > data_variants.aggregates_pools.size())
         for (size_t i = data_variants.aggregates_pools.size(); i < max_threads; ++i)
             data_variants.aggregates_pools.push_back(std::make_shared<Arena>());
@@ -1133,6 +1134,7 @@ BlocksList Aggregator::prepareBlocksAndFillTwoLevelImpl(
             /// Select Arena to avoid race conditions
             Arena * arena = data_variants.aggregates_pools.at(thread_id).get();
             blocks.emplace_back(convertOneBucketToBlock(data_variants, method, arena, final, bucket));
+            adaptive_yield();
         }
         return blocks;
     };
@@ -1140,6 +1142,7 @@ BlocksList Aggregator::prepareBlocksAndFillTwoLevelImpl(
     /// packaged_task is used to ensure that exceptions are automatically thrown into the main stream.
 
     std::vector<std::packaged_task<BlocksList()>> tasks(max_threads);
+    std::vector<boost::fibers::future<void>> futures;
 
     try
     {
@@ -1148,8 +1151,8 @@ BlocksList Aggregator::prepareBlocksAndFillTwoLevelImpl(
             tasks[thread_id] = std::packaged_task<BlocksList()>(
                 [thread_id, &converter] { return converter(thread_id); });
 
-            if (thread_pool)
-                thread_pool->schedule(ThreadFactory().newJob([thread_id, &tasks] { tasks[thread_id](); }));
+            if (max_threads > 1)
+                futures.push_back(DefaultFiberPool::submit_job([thread_id, &tasks] { tasks[thread_id](); }).value());
             else
                 tasks[thread_id]();
         }
@@ -1157,14 +1160,14 @@ BlocksList Aggregator::prepareBlocksAndFillTwoLevelImpl(
     catch (...)
     {
         /// If this is not done, then in case of an exception, tasks will be destroyed before the threads are completed, and it will be bad.
-        if (thread_pool)
-            thread_pool->wait();
+        for (auto & f : futures)
+            f.wait();
 
         throw;
     }
 
-    if (thread_pool)
-        thread_pool->wait();
+    for (auto & f : futures)
+        f.wait();
 
     BlocksList blocks;
 
@@ -1195,10 +1198,9 @@ BlocksList Aggregator::convertToBlocks(AggregatedDataVariants & data_variants, b
     if (data_variants.empty())
         return blocks;
 
-    std::unique_ptr<ThreadPool> thread_pool;
-    if (max_threads > 1 && data_variants.sizeWithoutOverflowRow() > 100000 /// TODO Make a custom threshold.
-        && data_variants.isTwoLevel()) /// TODO Use the shared thread pool with the `merge` function.
-        thread_pool = std::make_unique<ThreadPool>(max_threads);
+    if (data_variants.sizeWithoutOverflowRow() <= 100000 /// TODO Make a custom threshold.
+        || data_variants.isTwoLevel())
+        max_threads = 1;
 
     if (isCancelled())
         return BlocksList();
@@ -1217,7 +1219,7 @@ BlocksList Aggregator::convertToBlocks(AggregatedDataVariants & data_variants, b
         if (!data_variants.isTwoLevel())
             blocks.emplace_back(prepareBlockAndFillSingleLevel(data_variants, final));
         else
-            blocks.splice(blocks.end(), prepareBlocksAndFillTwoLevel(data_variants, final, thread_pool.get()));
+            blocks.splice(blocks.end(), prepareBlocksAndFillTwoLevel(data_variants, final, max_threads));
     }
 
     if (!final)
@@ -1454,7 +1456,8 @@ class MergingAndConvertingBlockInputStream : public IProfilingBlockInputStream
         /// We need to wait for threads to finish before destructor of 'parallel_merge_data',
         ///  because the threads access 'parallel_merge_data'.
         if (parallel_merge_data)
-            parallel_merge_data->pool.wait();
+            for (auto & f : parallel_merge_data->futures)
+                f.wait();
     }
 
 protected:
@@ -1517,7 +1520,7 @@ class MergingAndConvertingBlockInputStream : public IProfilingBlockInputStream
 
             while (true)
             {
-                std::unique_lock<std::mutex> lock(parallel_merge_data->mutex);
+                std::unique_lock lock(parallel_merge_data->mutex);
 
                 if (parallel_merge_data->exception)
                     std::rethrow_exception(parallel_merge_data->exception);
@@ -1558,12 +1561,11 @@ class MergingAndConvertingBlockInputStream : public IProfilingBlockInputStream
     {
         std::map<Int32, Block> ready_blocks;
         std::exception_ptr exception;
-        std::mutex mutex;
-        std::condition_variable condvar;
-        ThreadPool pool;
+        boost::fibers::mutex mutex;
+        boost::fibers::condition_variable condvar;
+        std::vector<boost::fibers::future<void>> futures;
 
-        explicit ParallelMergeData(size_t threads)
-            : pool(threads)
+        explicit ParallelMergeData(size_t)
         {}
     };
 
@@ -1575,8 +1577,7 @@ class MergingAndConvertingBlockInputStream : public IProfilingBlockInputStream
         if (num >= NUM_BUCKETS)
             return;
 
-        parallel_merge_data->pool.schedule(
-            ThreadFactory(true, "MergingAggregtd").newJob([this, num] { thread(num); }));
+        parallel_merge_data->futures.push_back(DefaultFiberPool::submit_job([this, num] { thread(num); }).value());
     }
 
     void thread(Int32 bucket_num)
@@ -1606,12 +1607,12 @@ class MergingAndConvertingBlockInputStream : public IProfilingBlockInputStream
             APPLY_FOR_VARIANTS_TWO_LEVEL(M)
 #undef M
 
-            std::lock_guard<std::mutex> lock(parallel_merge_data->mutex);
+            std::lock_guard lock(parallel_merge_data->mutex);
             parallel_merge_data->ready_blocks[bucket_num] = std::move(block);
         }
         catch (...)
         {
-            std::lock_guard<std::mutex> lock(parallel_merge_data->mutex);
+            std::lock_guard lock(parallel_merge_data->mutex);
             if (!parallel_merge_data->exception)
                 parallel_merge_data->exception = std::current_exception();
         }
@@ -1912,6 +1913,9 @@ void Aggregator::mergeStream(const BlockInputStreamPtr & stream, AggregatedDataV
     auto max_bucket = bucket_to_blocks.rbegin()->first;
     size_t has_two_level = max_bucket > 0;
 
+    if (total_input_rows <= 100000 || !has_two_level)
+        max_threads = 1;
+
     if (has_two_level)
     {
 #define M(NAME)                                              \
@@ -1961,14 +1965,12 @@ void Aggregator::mergeStream(const BlockInputStreamPtr & stream, AggregatedDataV
                 APPLY_FOR_VARIANTS_TWO_LEVEL(M)
 #undef M
                 else throw Exception("Unknown aggregated data variant.", ErrorCodes::UNKNOWN_AGGREGATED_DATA_VARIANT);
+
+                adaptive_yield();
             }
         };
 
-        std::unique_ptr<ThreadPool> thread_pool;
-        if (max_threads > 1 && total_input_rows > 100000 /// TODO Make a custom threshold.
-            && has_two_level)
-            thread_pool = std::make_unique<ThreadPool>(max_threads);
-
+        std::vector<boost::fibers::future<void>> futures;
         for (const auto & bucket_blocks : bucket_to_blocks)
         {
             const auto bucket = bucket_blocks.first;
@@ -1981,14 +1983,14 @@ void Aggregator::mergeStream(const BlockInputStreamPtr & stream, AggregatedDataV
 
             auto task = std::bind(merge_bucket, bucket, aggregates_pool);
 
-            if (thread_pool)
-                thread_pool->schedule(ThreadFactory().newJob(task));
+            if (max_threads > 1)
+                futures.push_back(DefaultFiberPool::submit_job(task).value());
             else
                 task();
         }
 
-        if (thread_pool)
-            thread_pool->wait();
+        for (auto & f : futures)
+            f.wait();
 
         LOG_TRACE(log, "Merged partially aggregated two-level data.");
     }
diff --git a/dbms/src/Interpreters/Aggregator.h b/dbms/src/Interpreters/Aggregator.h
index aa2a2a13072..e736f6b7918 100644
--- a/dbms/src/Interpreters/Aggregator.h
+++ b/dbms/src/Interpreters/Aggregator.h
@@ -892,7 +892,7 @@ class Aggregator
     /// How many RAM were used to process the query before processing the first block.
     Int64 memory_usage_before_aggregation = 0;
 
-    std::mutex mutex;
+    boost::fibers::mutex mutex;
 
     Poco::Logger * log = &Poco::Logger::get("Aggregator");
 
@@ -1034,14 +1034,14 @@ class Aggregator
 
     Block prepareBlockAndFillWithoutKey(AggregatedDataVariants & data_variants, bool final, bool is_overflows) const;
     Block prepareBlockAndFillSingleLevel(AggregatedDataVariants & data_variants, bool final) const;
-    BlocksList prepareBlocksAndFillTwoLevel(AggregatedDataVariants & data_variants, bool final, ThreadPool * thread_pool) const;
+    BlocksList prepareBlocksAndFillTwoLevel(AggregatedDataVariants & data_variants, bool final, size_t max_threads) const;
 
     template <typename Method>
     BlocksList prepareBlocksAndFillTwoLevelImpl(
         AggregatedDataVariants & data_variants,
         Method & method,
         bool final,
-        ThreadPool * thread_pool) const;
+        size_t max_threads) const;
 
     template <bool no_more_keys, typename Method, typename Table>
     void mergeStreamsImplCase(
diff --git a/dbms/src/Interpreters/Join.cpp b/dbms/src/Interpreters/Join.cpp
index 639464ed9f6..ae86e64d5d9 100644
--- a/dbms/src/Interpreters/Join.cpp
+++ b/dbms/src/Interpreters/Join.cpp
@@ -98,7 +98,7 @@ Join::Join(const Names & key_names_left_, const Names & key_names_right_, bool u
 
 void Join::setFinishBuildTable(bool finish_)
 {
-    std::lock_guard<std::mutex> lk(build_table_mutex);
+    std::lock_guard lk(build_table_mutex);
     have_finish_build = finish_;
     build_table_cv.notify_all();
 }
@@ -576,7 +576,7 @@ void NO_INLINE insertFromBlockImplTypeCaseWithLock(
         }
         else
         {
-            std::lock_guard<std::mutex> lk(map.getSegmentMutex(segment_index));
+            std::lock_guard lk(map.getSegmentMutex(segment_index));
             for (size_t i = 0; i < segment_index_info[segment_index].size(); i++)
             {
                 Inserter<STRICTNESS, typename Map::SegmentType::HashTable, KeyGetter>::insert(map.getSegmentTable(segment_index), key_getter, stored_block, segment_index_info[segment_index][i], pool, sort_key_containers);
@@ -732,7 +732,7 @@ void Join::insertFromBlock(const Block & block, size_t stream_index)
     std::shared_lock lock(rwlock);
     Block * stored_block = nullptr;
     {
-        std::lock_guard<std::mutex> lk(blocks_lock);
+        std::lock_guard lk(blocks_lock);
         blocks.push_back(block);
         stored_block = &blocks.back();
         original_blocks.push_back(block);
diff --git a/dbms/src/Interpreters/Join.h b/dbms/src/Interpreters/Join.h
index f8586a1a929..b77eab87746 100644
--- a/dbms/src/Interpreters/Join.h
+++ b/dbms/src/Interpreters/Join.h
@@ -4,6 +4,8 @@
 #include <Columns/ColumnNullable.h>
 #include <Columns/ColumnString.h>
 #include <Common/Arena.h>
+#include <Common/FiberPool.hpp>
+#include <Common/FiberRWLock.h>
 #include <Common/HashTable/HashMap.h>
 #include <DataStreams/IBlockInputStream.h>
 #include <DataStreams/SizeLimits.h>
@@ -267,7 +269,7 @@ class Join
       */
     BlocksList blocks;
     /// mutex to protect concurrent insert to blocks
-    std::mutex blocks_lock;
+    boost::fibers::mutex blocks_lock;
     /// keep original block for concurrent build
     Blocks original_blocks;
 
@@ -296,8 +298,8 @@ class Join
     /// Block with key columns in the same order they appear in the right-side table.
     Block sample_block_with_keys;
 
-    mutable std::mutex build_table_mutex;
-    mutable std::condition_variable build_table_cv;
+    mutable boost::fibers::mutex build_table_mutex;
+    mutable boost::fibers::condition_variable build_table_cv;
     bool have_finish_build;
 
     Poco::Logger * log;
@@ -311,7 +313,7 @@ class Join
       *  and StorageJoin only calls these two methods.
       * That's why another methods are not guarded.
       */
-    mutable std::shared_mutex rwlock;
+    mutable FiberRWLock rwlock;
 
     void init(Type type_);
 
diff --git a/dbms/src/Interpreters/ProcessList.cpp b/dbms/src/Interpreters/ProcessList.cpp
index 30419509d0d..9d83fe82d4f 100644
--- a/dbms/src/Interpreters/ProcessList.cpp
+++ b/dbms/src/Interpreters/ProcessList.cpp
@@ -244,7 +244,7 @@ ProcessListEntry::~ProcessListEntry()
 
 void ProcessListElement::setQueryStreams(const BlockIO & io)
 {
-    std::lock_guard<std::mutex> lock(query_streams_mutex);
+    std::lock_guard lock(query_streams_mutex);
 
     query_stream_in = io.in;
     query_stream_out = io.out;
@@ -257,7 +257,7 @@ void ProcessListElement::releaseQueryStreams()
     BlockOutputStreamPtr out;
 
     {
-        std::lock_guard<std::mutex> lock(query_streams_mutex);
+        std::lock_guard lock(query_streams_mutex);
 
         query_streams_status = QueryStreamsStatus::Released;
         in = std::move(query_stream_in);
@@ -269,14 +269,14 @@ void ProcessListElement::releaseQueryStreams()
 
 bool ProcessListElement::streamsAreReleased()
 {
-    std::lock_guard<std::mutex> lock(query_streams_mutex);
+    std::lock_guard lock(query_streams_mutex);
 
     return query_streams_status == QueryStreamsStatus::Released;
 }
 
 bool ProcessListElement::tryGetQueryStreams(BlockInputStreamPtr & in, BlockOutputStreamPtr & out) const
 {
-    std::lock_guard<std::mutex> lock(query_streams_mutex);
+    std::lock_guard lock(query_streams_mutex);
 
     if (query_streams_status != QueryStreamsStatus::Initialized)
         return false;
diff --git a/dbms/src/Interpreters/ProcessList.h b/dbms/src/Interpreters/ProcessList.h
index 19cf01732d7..788c7de62cc 100644
--- a/dbms/src/Interpreters/ProcessList.h
+++ b/dbms/src/Interpreters/ProcessList.h
@@ -83,7 +83,7 @@ class ProcessListElement
     /// Be careful using it. For example, queries field could be modified concurrently.
     const ProcessListForUser * user_process_list = nullptr;
 
-    mutable std::mutex query_streams_mutex;
+    mutable boost::fibers::mutex query_streams_mutex;
 
     /// Streams with query results, point to BlockIO from executeQuery()
     /// This declaration is compatible with notes about BlockIO::process_list_entry:
@@ -111,7 +111,7 @@ class ProcessListElement
         priority_handle(std::move(priority_handle_))
     {
         memory_tracker.setDescription("(for query)");
-        current_memory_tracker = &memory_tracker;
+        // current_memory_tracker = &memory_tracker;
 
         if (memory_tracker_fault_probability)
             memory_tracker.setFaultProbability(memory_tracker_fault_probability);
diff --git a/dbms/src/Interpreters/SharedQueries.h b/dbms/src/Interpreters/SharedQueries.h
index c7e83ebf446..d7383f45e42 100644
--- a/dbms/src/Interpreters/SharedQueries.h
+++ b/dbms/src/Interpreters/SharedQueries.h
@@ -113,7 +113,7 @@ class SharedQueries
         else
         {
             BlockIO io = creator();
-            io.in = std::make_shared<SharedQueryBlockInputStream>(clients, io.in, nullptr);
+            io.in = std::make_shared<SharedQueryBlockInputStream>(clients, io.in, nullptr, true);
             queries.emplace(query_id, std::make_shared<SharedQuery>(query_id, clients, io.in));
 
             LOG_TRACE(log, "getOrCreateBlockIO, query_id: " << query_id << ", clients: " << clients << ", connected_clients: " << 1);
